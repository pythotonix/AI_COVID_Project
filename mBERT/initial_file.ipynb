{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sBPygoseOJ7w",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBPygoseOJ7w",
        "outputId": "8c921bec-b7da-4b73-c294-72a732baff2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.5.0 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\n",
            "mizani 0.13.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "plotnine 0.14.5 requires pandas>=2.2.0, but you have pandas 2.1.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "xarray 2025.11.0 requires pandas>=2.2, but you have pandas 2.1.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install pandas==2.1.4 numpy==1.26.4 pyarrow==15.0.2 seaborn==0.13.2 \\\n",
        "    \"protobuf<5.0.0\" \"transformers==4.44.2\" \"datasets==2.20.0\" \\\n",
        "    \"sentencepiece>=0.1.99\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-MEdXH964SEt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MEdXH964SEt",
        "outputId": "09bfe64e-0d00-44cd-d535-538c3371934b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers: 4.44.2\n",
            "datasets: 2.20.0\n",
            "accelerate: 1.12.0\n",
            "protobuf: 4.25.8\n",
            "transformers module path: /usr/local/lib/python3.12/dist-packages/transformers/__init__.py\n"
          ]
        }
      ],
      "source": [
        "import transformers, datasets, accelerate, google.protobuf as gp, sys\n",
        "print(\"transformers:\", transformers.__version__)\n",
        "print(\"datasets:\", datasets.__version__)\n",
        "print(\"accelerate:\", accelerate.__version__)\n",
        "print(\"protobuf:\", gp.__version__)\n",
        "print(\"transformers module path:\", transformers.__file__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12234601",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12234601",
        "outputId": "ef05f1fe-3915-4a06-a042-37b6f41c7217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import os, json, re, urllib.request, warnings, random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "BASE_DIR = \"/content/drive/MyDrive/covid-sentiment\"\n",
        "os.makedirs(BASE_DIR, exist_ok=True)\n",
        "CSV_PATH = \"/content/covid_instagram.csv\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "qgkWazhE42Y4",
      "metadata": {
        "id": "qgkWazhE42Y4"
      },
      "source": [
        "\n",
        "###  Select language configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7179f02b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7179f02b",
        "outputId": "3a7d63cf-dc40-45eb-885d-9beebcdfffb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing language: {'code': 'en', 'full': 'english', 'stopwords_code': 'en', 'tag': 'en'}\n"
          ]
        }
      ],
      "source": [
        "LANG = {\n",
        "    \"code\": \"en\",             # \"en\",\"es\",\"pt\",\"hi\",\"id\"\n",
        "    \"full\": \"english\",\n",
        "    \"stopwords_code\": \"en\",\n",
        "    \"tag\": \"en\"\n",
        "}\n",
        "SAVE_LANG_DIR = f\"{BASE_DIR}/{LANG['tag']}\"\n",
        "os.makedirs(SAVE_LANG_DIR, exist_ok=True)\n",
        "print(\"Preparing language:\", LANG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d03f3dc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d03f3dc0",
        "outputId": "b98c9136-c601-4899-f4d5-b6c236134932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: {'negative': 0, 'neutral': 1, 'positive': 2}\n",
            "Total rows: 343041\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "def cf(x): return str(x).casefold()\n",
        "\n",
        "df = df[(df[\"Language Code\"].astype(str).map(cf) == LANG[\"code\"]) |\n",
        "        (df[\"Full Language\"].astype(str).map(cf) == LANG[\"full\"])].copy()\n",
        "\n",
        "text_col  = \"Post Description\"\n",
        "label_col = \"Sentiment\"\n",
        "df = df.dropna(subset=[text_col, label_col])\n",
        "df = df[df[text_col].astype(str).str.strip().str.len() > 0].copy()\n",
        "\n",
        "STOPWORDS_URL = f\"https://raw.githubusercontent.com/stopwords-iso/stopwords-{LANG['stopwords_code']}/master/stopwords-{LANG['stopwords_code']}.txt\"\n",
        "STOPWORDS_PATH = f\"/content/stopwords_{LANG['stopwords_code']}.txt\"\n",
        "try:\n",
        "    if not os.path.exists(STOPWORDS_PATH):\n",
        "        urllib.request.urlretrieve(STOPWORDS_URL, STOPWORDS_PATH)\n",
        "    with open(STOPWORDS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "        LANG_STOPWORDS = set(w.strip() for w in f if w.strip())\n",
        "except Exception:\n",
        "    LANG_STOPWORDS = set()\n",
        "\n",
        "URL_RE        = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
        "MENTION_RE    = re.compile(r\"@\\w+\")\n",
        "HASHTAG_RE    = re.compile(r\"#(\\w+)\", flags=re.UNICODE)\n",
        "HTML_RE       = re.compile(r\"&\\w+;\")\n",
        "MULTISPACE_RE = re.compile(r\"\\s+\")\n",
        "\n",
        "def basic_clean(text: str) -> str:\n",
        "    t = text if isinstance(text, str) else \"\"\n",
        "    t = URL_RE.sub(\" \", t)\n",
        "    t = MENTION_RE.sub(\" \", t)\n",
        "    t = HTML_RE.sub(\" \", t)\n",
        "    t = HASHTAG_RE.sub(r\"\\1\", t)\n",
        "    t = MULTISPACE_RE.sub(\" \", t)\n",
        "    return t.strip()\n",
        "\n",
        "def remove_stopwords(text: str, stopwords: set) -> str:\n",
        "    toks = text.split()\n",
        "    return \" \".join(tok for tok in toks if tok.casefold() not in stopwords)\n",
        "\n",
        "df[\"text_clean\"] = df[text_col].astype(str).apply(basic_clean)\n",
        "if LANG_STOPWORDS:\n",
        "    df[\"text_clean\"] = df[\"text_clean\"].apply(lambda s: remove_stopwords(s, LANG_STOPWORDS))\n",
        "\n",
        "labels_raw = df[label_col].astype(str).map(cf)\n",
        "label_names = sorted(labels_raw.unique().tolist())\n",
        "label2id = {lbl:i for i,lbl in enumerate(label_names)}\n",
        "id2label = {i:lbl for lbl,i in label2id.items()}\n",
        "df[\"label\"] = labels_raw.map(label2id)\n",
        "\n",
        "print(\"Classes:\", label2id)\n",
        "print(\"Total rows:\", len(df))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0c6ec40",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0c6ec40",
        "outputId": "a041f7b9-e8f2-4003-b383-4c606a82327c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original train counts: {0: 38183, 1: 91271, 2: 127826}\n",
            "Balanced train counts: {0: 91271, 1: 91271, 2: 91271}\n"
          ]
        }
      ],
      "source": [
        "train_df, test_df = train_test_split(\n",
        "    df[[\"text_clean\", \"label\"]],\n",
        "    test_size=0.25,\n",
        "    random_state=SEED,\n",
        "    stratify=df[\"label\"]\n",
        ")\n",
        "print(\"Original train counts:\", train_df[\"label\"].value_counts().sort_index().to_dict())\n",
        "\n",
        "def make_class_balanced_train(train_df, label_col=\"label\",\n",
        "                              target_per_class=None, max_cap_per_class=None,\n",
        "                              random_state=SEED):\n",
        "    counts = train_df[label_col].value_counts().sort_index()\n",
        "    if target_per_class is None:\n",
        "        target_per_class = int(np.median(counts.values))\n",
        "    if max_cap_per_class is not None:\n",
        "        target_per_class = min(target_per_class, int(max_cap_per_class))\n",
        "    target_per_class = max(target_per_class, 1)\n",
        "\n",
        "    parts=[]\n",
        "    for cls, cnt in counts.items():\n",
        "        df_c = train_df[train_df[label_col]==cls]\n",
        "        if cnt > target_per_class:\n",
        "            df_c_bal = resample(df_c, replace=False, n_samples=target_per_class, random_state=random_state)\n",
        "        elif cnt < target_per_class:\n",
        "            df_c_bal = resample(df_c, replace=True,  n_samples=target_per_class, random_state=random_state)\n",
        "        else:\n",
        "            df_c_bal = df_c\n",
        "        parts.append(df_c_bal)\n",
        "    out = pd.concat(parts, axis=0).sample(frac=1.0, random_state=random_state).reset_index(drop=True)\n",
        "    return out\n",
        "\n",
        "BAL_CAP = None\n",
        "train_bal_df = make_class_balanced_train(train_df.copy(), label_col=\"label\",\n",
        "                                         target_per_class=None, max_cap_per_class=BAL_CAP,\n",
        "                                         random_state=SEED)\n",
        "print(\"Balanced train counts:\", train_bal_df[\"label\"].value_counts().sort_index().to_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "115bc1fe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "a62748758b3943fe9be2b1f747beb935",
            "591ba13de1784f11ae972a13a8622334",
            "a5b26c055f68421ca42a5c208714bab6",
            "36ee608bfeb64a0b8f6fddb5eff4395f",
            "589118d1247e47cba74d3a6171500758",
            "ed1c4427c2cc4749af5606387a1078ea",
            "8a57b4e750314264b9d4381765a87f63",
            "9fc07d0390614c31ae8072eb848e3564",
            "aad5f7429f2a406d93e87483372c96c0",
            "857ceb081bc849b4bd7d39c1805b1d27",
            "d6b406f5c22248d7aa1b1938e7b32a99",
            "c9cf3c6460b74388aa49e745be4c1483",
            "c74b7d9472dd4e6da2e62c282c043f1f",
            "df0c8c191d1b4d55a2ea1a6fbc1b2b3c",
            "ed505cbfafa440978ca91b530c258ade",
            "93f2b3c1c6944656983a01653e99350f",
            "965ca2cdd6f44c84bdc34e114f7ae91d",
            "8a05e805762646918185210416b99fe1",
            "e35d61c9f6314d2091433ea3a0f4e4ed",
            "75b91f7dd1654ad5ab4d532c1b3f0256",
            "c584c6f0a58a429e84772d78c1e26869",
            "e71e742aafd24f5bb5996c2080aa8f1d",
            "99817e789c6e42bc9d648bd91094e813",
            "7b118a102e594a098fcab2d9250ea60a",
            "36c91e9118d6463f9d4e6518e605eef3",
            "dfe8a117895f46bdabfa127f6ffc0b72",
            "0872a3fce61b4bc3accf7911b30fbc03",
            "09e2091af7a54b40b87a84d5cf8b0d6e",
            "d350e3731b32424798bbbac114b05553",
            "16748fbb66694a67be30225176ca3095",
            "b7bad59582f848a393899a1eb428c70f",
            "fdc9ecd9cbfc448c8c4f8499e8baa6be",
            "c52e0996ce5842228b1302f100e5bbb9",
            "b2ffdcb7bae1438e919cea8f03fe1097",
            "a0a98f90b454455582a7827b46816436",
            "908486a2a939474585428d051eed33f2",
            "1f8e9e475da24c90a61f557813771383",
            "ac126cbf0d274dcdbb2f98393c0bfe6c",
            "39b614f16c4d48c8a16b8300d82a202b",
            "1647dc61f2434504bfccf019c99d419d",
            "7ab716b455ae4ba9a295ac762d941d24",
            "2e8870572683463aaeddabdef2489f08",
            "3e7c11213b8a4951bc05b36ca6045013",
            "fb614324213e4271b9db43240f867a8b",
            "9073c044f2624b16b6f66d392524944b",
            "c15a9a093960464395a8f1184166d4bc",
            "f296f5ec217b47058a740cd18bfa9a79",
            "4956fcd3d48548a48605df243484850c",
            "1d709c0890ee4179913f98d91db5101c",
            "0cc6886e2def44b5ac9dc20d4c153422",
            "fc98a9957b4847d59d3d64432b184f5b",
            "0a7f848b0927486995cc949cd1946647",
            "0af4310db28141b4ba49c57311fc2111",
            "1d0b5744868d48db95590d6f6c5f26db",
            "6296735499994208a845e3448de5bde6",
            "16b356de7c4448daaa9c27b10a06f4ca",
            "1195668a884f4a2e8ea1c36bfcd08dc1",
            "0fece7e0de954193adaf0afa723c8af8",
            "b2fca34122124c05a8aed8d20e63bec7",
            "401e1a062dce4992b712f7ec0aad77e7",
            "63f5e7f0ec85430a973b29cc702465af",
            "467ee06ffb174e3d9c727392125355ce",
            "b8b78619b4ae41dea47f27bb86a580fd",
            "b85a33234fbd4f85a26e08ab48592b23",
            "8c16b6e969ac47b883788b0278811ac4",
            "87b781b1da3944bca7f7221b9b014044",
            "9bba28f028524f8e84b01b5e0da09e0c",
            "44b93c9c55ec4318a07d6ea6dcc14cb7",
            "ec5ab6972db84bcab2202d8fc8b84ac2",
            "67c3346879ff4fc88ad19a0ee68e23ae",
            "d98cd2939e574c33b6be64984d1f2fcd",
            "0204eb68ab184d25b237e54fe05f47c1",
            "2c910a0147464c35be8672f5b8bd01b1",
            "4b16a9810caa4315922007ca37a7d9ba",
            "f4e123475c754408892c9c30974ced2d",
            "7258be7297a24d5a85df60488a7afac6",
            "15e0f2ba9f814f218df4896aaeed8bf0",
            "2a24a24d42134781a09415930075cc99",
            "715835a4cd37434885ec81d6d320716a",
            "4a0409443e01479994b80082b922fc85",
            "2f7e4fb4d0c1405b9394e042f621260e",
            "dc381be2ac424dbeb943c7e4d1ff6885",
            "94c2cf026c654889a8d53184cded79c3",
            "dff680e1a8a740e489f809b4825b58af",
            "1d6eb3ea04824c63a790346335855c2a",
            "4ac219eb1eeb40439d28298622bea565",
            "7a648e0782914e4f909f410972b7942a",
            "c4e944f7927840b781b555751e3dfbc7"
          ]
        },
        "id": "115bc1fe",
        "outputId": "3b6cd14c-25b1-4048-bcf4-82ead2f75d0b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a62748758b3943fe9be2b1f747beb935"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9cf3c6460b74388aa49e745be4c1483"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "99817e789c6e42bc9d648bd91094e813"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2ffdcb7bae1438e919cea8f03fe1097"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/273813 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9073c044f2624b16b6f66d392524944b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/85761 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16b356de7c4448daaa9c27b10a06f4ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/273813 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bba28f028524f8e84b01b5e0da09e0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Saving the dataset (0/1 shards):   0%|          | 0/85761 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a24a24d42134781a09415930075cc99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved tokenized dataset to: /content/drive/MyDrive/covid-sentiment_/en/tok_mbert_256\n"
          ]
        }
      ],
      "source": [
        "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "def tokenize_batch(batch):\n",
        "    return tokenizer(batch[\"text_clean\"], truncation=True, padding=False, max_length=256)\n",
        "\n",
        "train_ds = Dataset.from_pandas(train_bal_df.reset_index(drop=True))\n",
        "test_ds  = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
        "raw = DatasetDict({\"train\": train_ds, \"test\": test_ds})\n",
        "\n",
        "tok = raw.map(tokenize_batch, batched=True, remove_columns=[\"text_clean\"])\n",
        "tok = tok.rename_column(\"label\", \"labels\")\n",
        "tok.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "TOK_DIR = f\"{SAVE_LANG_DIR}/tok_mbert_256\"\n",
        "tok.save_to_disk(TOK_DIR)\n",
        "print(\"Saved tokenized dataset to:\", TOK_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32f5f532",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32f5f532",
        "outputId": "3f31d672-5d8e-4ffa-9f91-b1048c75e871"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All artifacts saved in: /content/drive/MyDrive/covid-sentiment_/en\n"
          ]
        }
      ],
      "source": [
        "train_bal_df.to_parquet(f\"{SAVE_LANG_DIR}/train_bal.parquet\", index=False)\n",
        "test_df.to_parquet(     f\"{SAVE_LANG_DIR}/test.parquet\",      index=False)\n",
        "\n",
        "with open(f\"{SAVE_LANG_DIR}/label2id.json\",\"w\",encoding=\"utf-8\") as f: json.dump(label2id,f,ensure_ascii=False,indent=2)\n",
        "with open(f\"{SAVE_LANG_DIR}/id2label.json\",\"w\",encoding=\"utf-8\") as f: json.dump(id2label,f,ensure_ascii=False,indent=2)\n",
        "with open(f\"{SAVE_LANG_DIR}/meta.json\",\"w\",encoding=\"utf-8\") as f:\n",
        "    json.dump({\"lang\": LANG, \"seed\": SEED, \"bal_cap\": BAL_CAP}, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"All artifacts saved in:\", SAVE_LANG_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50XLVTbs9ssp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50XLVTbs9ssp",
        "outputId": "22559cf4-05dd-4203-a700-d1ab775933d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/covid-sentiment_\n",
            "\tzip warning: name not matched: i\n",
            "\tzip warning: name not matched: covid-sentiment_\n",
            "  adding: en/ (stored 0%)\n",
            "  adding: en/tok_mbert_256/ (stored 0%)\n",
            "  adding: en/tok_mbert_256/dataset_dict.json (stored 0%)\n",
            "  adding: en/tok_mbert_256/train/ (stored 0%)\n",
            "  adding: en/tok_mbert_256/train/data-00000-of-00001.arrow (deflated 73%)\n",
            "  adding: en/tok_mbert_256/train/state.json (deflated 40%)\n",
            "  adding: en/tok_mbert_256/train/dataset_info.json (deflated 71%)\n",
            "  adding: en/tok_mbert_256/test/ (stored 0%)\n",
            "  adding: en/tok_mbert_256/test/data-00000-of-00001.arrow (deflated 73%)\n",
            "  adding: en/tok_mbert_256/test/state.json (deflated 39%)\n",
            "  adding: en/tok_mbert_256/test/dataset_info.json (deflated 71%)\n",
            "  adding: en/train_bal.parquet (deflated 14%)\n",
            "  adding: en/test.parquet (deflated 14%)\n",
            "  adding: en/label2id.json (deflated 23%)\n",
            "  adding: en/id2label.json (deflated 24%)\n",
            "  adding: en/meta.json (deflated 34%)\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/covid-sentiment\"\n",
        "# !zip -r save_filename.extension . i folder_location_to_zip\n",
        "!zip -r folder_full.zip . i covid-sentiment"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}